# ðŸ¤– Capstone Project â€“ Customer Satisfaction (CSAT) Prediction using Deep Learning

This project focuses on predicting **Customer Satisfaction (CSAT)** scores using a Deep Learning Artificial Neural Network (ANN). The goal is to enhance service quality and customer retention by forecasting satisfaction levels based on support interactions in an e-commerce setting.

---

## ðŸ“Œ Project Summary

Traditional survey-based methods of measuring CSAT can be slow and limited. In this project, we use historical customer support data from Shopzilla's e-commerce platform and apply deep learning techniques to **predict whether a customer is satisfied or not** based on interaction features.

---

## ðŸŽ¯ Objectives

- Predict CSAT scores (binary: **Satisfied = 5**, **Not Satisfied < 5**)
- Apply custom feature engineering and preprocessing
- Build and train a Deep Learning model using TensorFlow/Keras
- Deploy model using Flask API for real-time predictions

---

## ðŸ§  Technologies Used

- Python 3.x
- Pandas, NumPy
- Scikit-learn (`Pipeline`, `ColumnTransformer`)
- TensorFlow / Keras
- Matplotlib & Seaborn (for visualization)
- Flask (for deployment)
- Git, GitHub

---

## ðŸ“‚ Project Structure

â”œâ”€â”€ templates/ # Flask HTML templates (if using frontend)
â”œâ”€â”€ .gitignore # Ignoring unnecessary files like env folders
â”œâ”€â”€ CSAT.ipynb # Notebook for EDA, model training & analysis
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ agent_stats.csv # Agent performance stats (for feature engineering)
â”œâ”€â”€ supervisor_stats.csv # Supervisor performance stats
â”œâ”€â”€ app.py # Flask API code
â”œâ”€â”€ csat_model.h5 # Trained deep learning model (HDF5 format)
â”œâ”€â”€ csat_model.keras # Alternate Keras model format
â”œâ”€â”€ csat_pipeline.pkl # Preprocessing pipeline for training
â”œâ”€â”€ inference_preprocessor.py # Script for preprocessing during inference
â”œâ”€â”€ eCommerce_Customer_support_data.csv # Raw dataset
â”œâ”€â”€ feature_columns.pkl # Selected feature names used during training
â”œâ”€â”€ label_encoder.pkl # Trained LabelEncoder for 'Sub-category'
â”œâ”€â”€ robust_scaler.pkl # RobustScaler for skewed features
â”œâ”€â”€ standard_scaler.pkl # StandardScaler for normal features

## ðŸ§ª Features & Engineering

The following features are used to train the model:

- **Categorical:** Channel name, Category, Sub-category, Agent Name, Shift, Supervisor, Manager
- **Numerical:** Item price, Connected handling time, Agent/Supervisor stats
- **Datetime-derived:** Response time, Issue day of week, Issue hour, Order-issue gap
- **Textual:** Customer Remarks (optional for future embedding)

---

## âš™ï¸ Model Architecture (Keras)

- Input Layer with concatenated numeric and embedded categorical features
- Embedding Layer for high-cardinality categorical variables (like Sub-category)
- Dense layers with ReLU activation
- Dropout for regularization

## ðŸ§ª Model Evaluation

- **Accuracy**
- **Precision, Recall, F1-Score**
- **Confusion Matrix**
- Training vs Validation Loss plots

---

## ðŸ“ˆ Results & Insights

- Embedding layers improved performance for high-cardinality features
- Handling class imbalance using `class_weight` was essential
- Final model achieved promising results on test data

Mritunjay Mishra
Data Scientist | Python Developer | Educator
ðŸ“ Faridabad, India
